<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Takes time to be twisted, or not</title>
 <link href="/atom.xml" rel="self"/>
 <link href=""/>
 <updated>2016-04-04T12:20:22-05:00</updated>
 <id></id>
 <author>
   <name>Yuanhang Liu</name>
 </author>

 
 <entry>
   <title>基因的显隐性和人类基因组</title>
   <link href="/2016/04/01/The-human-reference-genome.html"/>
   <updated>2016-04-01T00:00:00-05:00</updated>
   <id>/2016/04/01/The human reference genome</id>
   <content type="html">&lt;p&gt;今天突然想到一个以前非常忽视的一个问题，这个问题涉及到显隐性遗传，最后涉及到人类基因组序列。首先人类是二倍体生物，也就是说每一个基因都会有两个拷贝，基因决定形状，所以决定某一性状的这一对基因就叫做等位基因（allele）。等位基因可以纯合子（homozygous）或者杂合子 (heterozygous) （也就是高中生物所教的AA，Aa）。纯合子的这一对等位基因序列相同，杂合子的不同。等位基因的这个特点决定了基因的显隐性遗传。&lt;/p&gt;

&lt;p&gt;这就牵扯到另外一个问题，因为一对杂合的等位基因的序列不同，所以最后要以哪个序列作为人类的参照基因组呢。&lt;/p&gt;

&lt;p&gt;要回答这个问题首先要了解人类基因组的测序的方法。到现在为止，人类的基因组其实只是选取了某一部分群体（貌似是十几个美国人）的DNA来做全基因组的测序。具体到测序方法，叫做clone-based (or hierarchical) approach。首先把一个个体的DNA打断为长度给40000-200000长度的片段，然后插入到质粒当中（比如bacterial artificial chromesome （BACs））。然后把质粒转入bacteria中扩增，然后运用NGS的方法进行测序。 就这样测出来的一个clone的序列叫做component。在测了很多clone的序列得到很多components之后，运用方法将这些component连接起来，最后组成一个长序列，叫做scaffolds。之后在运用方法将scaffolds连接成为染色体。&lt;/p&gt;

&lt;p&gt;所以说人类的基因组是好多个基因组的混合体（conglomeration）。也就没办法去区分序列到底是来自哪个allele了。这个问题还是需要解决的，因为并不是所有的基因两个allele的序列都是一样的，甚至两个allele都是表达的。但目前没有太好的解决办法。人类基因组目前也只是在某些区间会有定义为alternative loci（这些区间的序列在不同的人中区别太大，没法用一个序列来代表）。&lt;/p&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://ncbiinsights.ncbi.nlm.nih.gov/2013/06/05/the-human-reference-genome-understanding-the-new-genome-assemblies/&quot;&gt;http://ncbiinsights.ncbi.nlm.nih.gov/2013/06/05/the-human-reference-genome-understanding-the-new-genome-assemblies/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ncbi.nlm.nih.gov/assembly/basics/&quot;&gt;http://www.ncbi.nlm.nih.gov/assembly/basics/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ncbi.nlm.nih.gov/projects/genome/assembly/grc/human/&quot;&gt;http://www.ncbi.nlm.nih.gov/projects/genome/assembly/grc/human/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Parallel processing in R</title>
   <link href="/2015/08/18/Parallel-processing-in-R.html"/>
   <updated>2015-08-18T00:00:00-05:00</updated>
   <id>/2015/08/18/Parallel processing in R</id>
   <content type="html">&lt;h1 id=&quot;overview&quot;&gt;Overview&lt;/h1&gt;

&lt;p&gt;The CRAN Task View for &lt;a href=&quot;https://cran.r-project.org/web/views/HighPerformanceComputing.html&quot;&gt;high performance and parallel computing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Most of these packages cite or identify one or more of &lt;a href=&quot;https://cran.r-project.org/web/packages/snow/index.html&quot;&gt;snow&lt;/a&gt;, &lt;a href=&quot;https://cran.r-project.org/web/packages/Rmpi/index.html&quot;&gt;Rmpi&lt;/a&gt;, multicore, &lt;a href=&quot;https://cran.r-project.org/web/packages/foreach/index.html&quot;&gt;foreach&lt;/a&gt; as relevant parallelization infratructure. Here we will focus on snow, multicore and parallel (Basically a combination of snow and multicore) packages&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;snow: 
Simple Network of Workstations, parallel processing is made possible Via &lt;code&gt;system(&quot;Rscript&quot;)&lt;/code&gt; or similar to launch a new process on the current machine or a similar machine with an identical R installation. Communication between master and worker processes is usually done via sockets. snow also takes advantage of fork and Rmpi mensioned below.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;multicore:
Parallel processing is made possible by forking, which creates a new R process by taking a complete copy of the master process.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Rmpi:
Using OS-level facilities to set up a means to send tasks to other members of a group of machines.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code&gt;detectCores&lt;/code&gt; is function used to detect number of phisical cores/CPUs in a system. The result is system dependent.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Parallel version of apply function, including &lt;code&gt;parLapply, parSapply, parApply, mclapply&lt;/code&gt; ect.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;benchmark-of-lapply-for-loop-foreach-dopar-foreach-do-parlapply-parsapply-in-various-scenarios&quot;&gt;Benchmark of &lt;code&gt;lapply, for loop, foreach dopar, foreach do, parLapply, parSapply&lt;/code&gt; in various scenarios&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Compare the performance of six methods for simple function &lt;code&gt;sqrt&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;library(doParallel)
library(doMC)
library(rbenchmark)
library(ggplot2)

cl &amp;lt;- makeCluster(4)
registerDoParallel(cl)
getDoParWorkers()
set.seed(1990)

FUN &amp;lt;- function(x) { round(sqrt(x), 4) }
a &amp;lt;- lapply(1:10, function(i) i)

test1 &amp;lt;- benchmark(&quot;lapply&quot; = lapply(1:10, FUN = FUN), 
                   &quot;For loop&quot; = for(i in 1:10){ FUN(i)},
                   &quot;Foreach dopar&quot; = foreach(i = 1:10) %dopar% FUN(i),
                   &quot;Foreach do&quot; = foreach(i = 1:10) %do% FUN(i),
                   &quot;parLapply&quot; = parLapply(cl = cl, X = a, fun = FUN),
                   &quot;parSapply&quot; = parSapply(cl = cl, X = a, FUN = FUN),
                   columns=c(&#39;test&#39;, &#39;elapsed&#39;, &#39;replications&#39;),
                   replications = c(100, 200, 500, 1000))

ggplot() +
  geom_line(aes(x = replications, y = elapsed, colour = test), data = test1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/media/2015-08-18-ParallelprocessinginR/benchmark1.png&quot; alt=&quot;p1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In this case, &lt;code&gt;for loop&lt;/code&gt; and &lt;code&gt;lappy&lt;/code&gt; seems to perform the best among other methods.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Compare the performance of six methods for matrix multiplication&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Element-wise multiplication&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FUN &amp;lt;- function(x){
  a &amp;lt;- matrix(rnorm(10000), 100, 100)
  b &amp;lt;- matrix(rnorm(10000), 100, 100)
  a * b
}

test2 &amp;lt;- benchmark(&quot;lapply&quot; = lapply(1:10, FUN = FUN), 
                   &quot;For loop&quot; = for(i in 1:10){ FUN(i)},
                   &quot;Foreach dopar&quot; = foreach(i = 1:10) %dopar% FUN(i),
                   &quot;Foreach do&quot; = foreach(i = 1:10) %do% FUN(i),
                   &quot;parLapply&quot; = parLapply(cl = cl, X = a, fun = FUN),
                   &quot;parSapply&quot; = parSapply(cl = cl, X = a, FUN = FUN),
                   columns=c(&#39;test&#39;, &#39;elapsed&#39;, &#39;replications&#39;),
                   replications = c(100, 200, 500, 1000))

ggplot() +
  geom_line(aes(x = replications, y = elapsed, colour = test), data = test2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/media/2015-08-18-ParallelprocessinginR/benchmark2.png&quot; alt=&quot;p2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In this case, &lt;code&gt;parLapply&lt;/code&gt; and &lt;code&gt;parSapply&lt;/code&gt; seems to perform the best, but not a significant increase in terms of efficiency since we used 4 cores.&lt;/p&gt;

&lt;p&gt;Inner product&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FUN &amp;lt;- function(x) {
  a &amp;lt;- matrix(rnorm(10000), 100, 100)
  b &amp;lt;- matrix(rnorm(10000), 100, 100)
  a %*% b
}

test3 &amp;lt;- benchmark(&quot;lapply&quot; = lapply(1:10, FUN = FUN), 
                   &quot;For loop&quot; = for(i in 1:10){ FUN(i)},
                   &quot;Foreach dopar&quot; = foreach(i = 1:10) %dopar% FUN(i),
                   &quot;Foreach do&quot; = foreach(i = 1:10) %do% FUN(i),
                   &quot;parLapply&quot; = parLapply(cl = cl, X = a, fun = FUN),
                   &quot;parSapply&quot; = parSapply(cl = cl, X = a, FUN = FUN),
                   columns=c(&#39;test&#39;, &#39;elapsed&#39;, &#39;replications&#39;),
                   replications = c(100, 200, 500, 1000))

ggplot() +
  geom_line(aes(x = replications, y = elapsed, colour = test), data = test3)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/media/2015-08-18-ParallelprocessinginR/benchmark3.png&quot; alt=&quot;p3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This time, &lt;code&gt;parLapply&lt;/code&gt; performed the best followed by &lt;code&gt;parSapply&lt;/code&gt;, but still not a significant increase in terms of efficiency since we used 4 cores.&lt;/p&gt;

&lt;p&gt;Inner productor with unbalanced dimensions&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FUN &amp;lt;- function(x) {
  a &amp;lt;- matrix(rnorm(10000), 1000, 10)
  b &amp;lt;- matrix(rnorm(10000), 10, 1000)
  a %*% b
}

test4 &amp;lt;- benchmark(&quot;lapply&quot; = lapply(1:10, FUN = FUN), 
                   &quot;For loop&quot; = for(i in 1:10){ FUN(i)},
                   &quot;Foreach dopar&quot; = foreach(i = 1:10) %dopar% FUN(i),
                   &quot;Foreach do&quot; = foreach(i = 1:10) %do% FUN(i),
                   &quot;parLapply&quot; = parLapply(cl = cl, X = a, fun = FUN),
                   &quot;parSapply&quot; = parSapply(cl = cl, X = a, FUN = FUN),
                   columns=c(&#39;test&#39;, &#39;elapsed&#39;, &#39;replications&#39;),
                   replications = c(10, 20, 50, 100))

ggplot() +
  geom_line(aes(x = replications, y = elapsed, colour = test), data = test4)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/media/2015-08-18-ParallelprocessinginR/benchmark4.png&quot; alt=&quot;p4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This time, &lt;code&gt;For loop, Foreach do, lapply&lt;/code&gt; performed much better than the other three methods. &lt;code&gt;parSapply&lt;/code&gt; performed the worst.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Compare the performance of six methods for fitting generalized linear model&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;FUN &amp;lt;- function(i) {
  ind &amp;lt;- sample(100, 100, replace=TRUE)
  result1 &amp;lt;- glm(Species~Sepal.Length, family=binomial(logit), data = iris[ind,])
  coefficients(result1)
}

test5 &amp;lt;- benchmark(&quot;lapply&quot; = lapply(1:10, FUN = FUN), 
                   &quot;For loop&quot; = for(i in 1:10){ FUN(i)},
                   &quot;Foreach dopar&quot; = foreach(i = 1:10) %dopar% FUN(i),
                   &quot;Foreach do&quot; = foreach(i = 1:10) %do% FUN(i),
                   &quot;parLapply&quot; = parLapply(cl = cl, X = a, fun = FUN),
                   &quot;parSapply&quot; = parSapply(cl = cl, X = a, FUN = FUN),
                   columns=c(&#39;test&#39;, &#39;elapsed&#39;, &#39;replications&#39;),
                   replications = c(100, 200, 500, 100))

ggplot() +
  geom_line(aes(x = replications, y = elapsed, colour = test), data = test5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/media/2015-08-18-ParallelprocessinginR/benchmark5.png&quot; alt=&quot;p5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This time, &lt;code&gt;parLapply&lt;/code&gt; and &lt;code&gt;parSapply&lt;/code&gt; performed the best. &lt;code&gt;Foreach do&lt;/code&gt; performed the worst&lt;/p&gt;

&lt;p&gt;&lt;code&gt;glm&lt;/code&gt; but in a list fashion&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a &amp;lt;- lapply(1:10, function(i) iris)

FUN &amp;lt;- function(x) {
  ind &amp;lt;- sample(100, 100, replace=TRUE)
  result1 &amp;lt;- glm(Species~Sepal.Length, family=binomial(logit), data = x[ind,])
  coefficients(result1)
}

test6 &amp;lt;- benchmark(&quot;lapply&quot; = lapply(a, FUN = FUN), 
                   &quot;For loop&quot; = for(i in 1:10){ FUN(a[[i]])},
                   &quot;Foreach dopar&quot; = foreach(i = 1:10) %dopar% FUN(a[[i]]),
                   &quot;Foreach do&quot; = foreach(i = 1:10) %do% FUN(a[[i]]),
                   &quot;parLapply&quot; = parLapply(cl = cl, X = a, fun = FUN),
                   &quot;parSapply&quot; = parSapply(cl = cl, X = a, FUN = FUN),
                   columns=c(&#39;test&#39;, &#39;elapsed&#39;, &#39;replications&#39;),
                   replications = c(100, 200, 500, 1000))

ggplot() +
  geom_line(aes(x = replications, y = elapsed, colour = test), data = test6)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/media/2015-08-18-ParallelprocessinginR/benchmark6.png&quot; alt=&quot;p6&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Not much difference compared to the previous one. &lt;code&gt;parLapply&lt;/code&gt; and &lt;code&gt;parSapply&lt;/code&gt; performed the best.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Using &lt;code&gt;doMC&lt;/code&gt; as the backend&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;registerDoMC(cores = 4)

test7 &amp;lt;- benchmark(&quot;lapply&quot; = lapply(a, FUN = FUN), 
                   &quot;For loop&quot; = for(i in 1:10){ FUN(a[[i]])},
                   &quot;Foreach dopar&quot; = foreach(i = 1:10) %dopar% FUN(a[[i]]),
                   &quot;Foreach do&quot; = foreach(i = 1:10) %do% FUN(a[[i]]),
                   &quot;parLapply&quot; = parLapply(cl = cl, X = a, fun = FUN),
                   &quot;parSapply&quot; = parSapply(cl = cl, X = a, FUN = FUN),
                   columns=c(&#39;test&#39;, &#39;elapsed&#39;, &#39;replications&#39;),
                   replications = c(100, 200, 500, 1000))

ggplot() +
  geom_line(aes(x = replications, y = elapsed, colour = test), data = test7)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/media/2015-08-18-ParallelprocessinginR/benchmark7.png&quot; alt=&quot;p7&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;parSapply&lt;/code&gt; and &lt;code&gt;parLapply&lt;/code&gt; still performed the best. Very interestingly, &lt;code&gt;foreach dopar&lt;/code&gt; performed the worst.&lt;/p&gt;

&lt;h1 id=&quot;to-summerize&quot;&gt;To summerize&lt;/h1&gt;
&lt;p&gt;Generally, &lt;code&gt;parLapply&lt;/code&gt; and &lt;code&gt;parSapply&lt;/code&gt; perform better than &lt;code&gt;foreach&lt;/code&gt;. However, for all parallel implementation methods, the increase in terms of efficiency is not propotional to the number of cores being used (Theoretical efficiency).&lt;/p&gt;

&lt;h1 id=&quot;session-information&quot;&gt;Session information&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;R version 3.2.3 (2015-12-10)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.1 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] ggplot2_2.1.0    rbenchmark_1.0.0 doMC_1.3.4       doParallel_1.0.8 iterators_1.0.7 
[6] foreach_1.4.2   

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.3      codetools_0.2-14 digest_0.6.9     grid_3.2.3       plyr_1.8.3      
 [6] gtable_0.2.0     scales_0.4.0     labeling_0.3     tools_3.2.3      munsell_0.4.3   
[11] compiler_3.2.3   colorspace_1.2-6
&lt;/code&gt;&lt;/pre&gt;

</content>
 </entry>
 
 <entry>
   <title>Comparison of differential expression methods for RNA-seq</title>
   <link href="/2015/08/02/Comparison-of-differential-expression-methods.html"/>
   <updated>2015-08-02T00:00:00-05:00</updated>
   <id>/2015/08/02/Comparison of differential expression methods</id>
   <content type="html">&lt;p&gt;This is mainly the summary results from ‘Comprehensive evaluation of differential gene expression analysis methods for RNA-seq data’ &lt;a href=&quot;http://www.genomebiology.com/2013/14/9/r95#B27&quot;&gt;http://www.genomebiology.com/2013/14/9/r95#B27&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;normalization&quot;&gt;Normalization&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;reads per kilobase per million reads (RPKM)&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;RPKM = ({10^9} \cdot C)/(N \cdot L)&lt;/script&gt;

&lt;p&gt;Where C stands for number of reads mapped to a gene (Number of fragments in terms of FPKM); N stands for total library size; L stands for gene length.&lt;/p&gt;

&lt;p&gt;RPKM and FPKM has some obvious limitations. RPKM and FPKM are both propotional to the real abundance of a transcript/isoform, however, for different experiments, the propotional ratio is not constant. This means that you need to do further normalization after RPKM or FPKM.&lt;/p&gt;

&lt;p&gt;All these methods have one limitations in common: It is relative abundance, which means the expression changes in one gene can also affect the relative abundance of other genes.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;TPM&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;TPM = p\cdot{10^6}&lt;/script&gt;

&lt;p&gt;Or can also be formulated by:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;TPM = \frac{FPKM\cdot{10^6}}{\sum FPKM}&lt;/script&gt;

&lt;p&gt;where p stands for the probablity of selecting a fragment from one transcirpt among all read counts. Different from RPKM/FPKM, TPM maesures estimated abundance rather than relative abundance. TPM is generally preferred than RPKM/FPKM&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;DESeq’s sizeFactors&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{s_j} = \underset{i}{median}\frac{k_{ij}}{\left(\prod_{v=1}^m k_{iv}\right)^{\frac 1m}}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Cuffdiff&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Similar to DESeq, firstly intro-condition scaling factor, secondly, across condition scaling factor.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Trimmed mean of M values (TMM)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;TMM is implemented in edgeR which computes a scaling factor between two experiments by using the weighted average of the subset of genes after excluding genes that exhibit high average read counts and genes that have large differences in expression.&lt;/p&gt;

&lt;p&gt;baySeq implements similar method as TMM; It uses genes with upper quantile in terms of expression levels to calculate scaling factor&lt;/p&gt;

&lt;p&gt;PoissonSeq use a subset of genes (Least differentially expressed between conditions) to calculate a scaling factor for normalization.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Quantile&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Very widely used normalization method for microarray, implemented in limmma; Basically ensure that the empirical distribution across all samples is the same.&lt;/p&gt;

&lt;h2 id=&quot;statistical-modeling&quot;&gt;Statistical modeling&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Poisson&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PoissonSeq&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Negative binomial&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To account for over-dispersion problem. DESeq and edgeR, DESeq and edgeR differs in terms of estimation of dispersion parameter (squared coefficient of variation).&lt;/p&gt;

&lt;p&gt;DESeq firstly models mean-variance relationship to get a better estimation of dispersion (squared coefficient of variation). For smaller number of replicates, additional apply a bias correction procedure for dispersion estimates.&lt;/p&gt;

&lt;p&gt;edgeR firstly estimate a common dispersion of all the genes, then applied a weighted maximum liklihood estimation of the weighted paramter of common dispersion and gene-wise dispersion, so that if the dispersion are very variable (different) across all the genes, the weight parameter should be very small, otherwise, it should be very big (to a common dispersion estimates)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;WL(\phi_g) = l_g(\phi_g) + \alpha \cdot l_C(\phi_g)&lt;/script&gt;

&lt;p&gt;Cufdiff models single isoform and multi-isoform differently; For single isoform, cufdiff applies a similar method as DESeq. Multi-isoform variance is modeled by a mixture model of negative binomials using the beta distribution parameters as mixture weights.&lt;/p&gt;

&lt;p&gt;baySeq implements a full Bayesian model of negative binomial distributions in which the prior probability parameters are estimated by numerical sampling from the data&lt;/p&gt;

&lt;h2 id=&quot;test-for-differential-expression&quot;&gt;Test for differential expression&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Fisher exact test for NB distribution&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Both DESeq and edgeR adopted a NB flavor fisher exact test&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p = \frac{\sum_{a+b=K_S \; p(a,b) \le p(K_A, K_B)} p(a,b)}{\sum_{a+b=K_S} p(a,b)}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;t test or moderated t test&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cuffdiff computes test statistics:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;T = \frac{E[log(y)]}{Var[log(y)]}&lt;/script&gt;

&lt;p&gt;This ratio approximately follows a normal distribution, a t test is applied to identify DEGs&lt;/p&gt;

&lt;p&gt;limma uses a moderated t-statistic to compute P values in which both the standard error and the degrees of freedom are modified&lt;/p&gt;

&lt;script&gt;
  (function(i,s,o,g,r,a,m){i[&#39;GoogleAnalyticsObject&#39;]=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,&#39;script&#39;,&#39;//www.google-analytics.com/analytics.js&#39;,&#39;ga&#39;);

  ga(&#39;create&#39;, &#39;UA-66197207-1&#39;, &#39;auto&#39;);
  ga(&#39;send&#39;, &#39;pageview&#39;);

&lt;/script&gt;

&lt;h2 id=&quot;references&quot;&gt;references&lt;/h2&gt;

&lt;p&gt;Lior Pachter’s talk &lt;a href=&quot;http://www.homolog.us/blogs/blog/2013/11/22/cshl-keynote-talk-lior-pachter/&quot;&gt;http://www.homolog.us/blogs/blog/2013/11/22/cshl-keynote-talk-lior-pachter/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Discussion of RPKM, FPKM and TPM on google groups &lt;a href=&quot;https://groups.google.com/forum/#!topic/rsem-users/GRyJfEOK1BQ&quot;&gt;https://groups.google.com/forum/#!topic/rsem-users/GRyJfEOK1BQ&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>BioC2015</title>
   <link href="/2015/07/19/BioC2015.html"/>
   <updated>2015-07-19T00:00:00-05:00</updated>
   <id>/2015/07/19/BioC2015</id>
   <content type="html">&lt;h1 id=&quot;bioc-day-1&quot;&gt;BioC Day 1&lt;/h1&gt;

&lt;p&gt;Some nite packages found on developer day Bioc2015&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;heatmap3&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;switchr: An R package for managing and seamlessly switching between sets of installed R packages. &lt;a href=&quot;https://cran.r-project.org/web/packages/switchr/index.html&quot;&gt;https://cran.r-project.org/web/packages/switchr/index.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;solr: General purpose R interface to Solr. &lt;a href=&quot;https://cran.r-project.org/web/packages/solr/index.html&quot;&gt;https://cran.r-project.org/web/packages/solr/index.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Rabix: to make bioinformatics pipelines. &lt;a href=&quot;https://www.rabix.org/&quot;&gt;https://www.rabix.org/&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;covr: Test coverage for packages. &lt;a href=&quot;https://cran.r-project.org/web/packages/covr/index.html&quot;&gt;https://cran.r-project.org/web/packages/covr/index.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;lintr: Statis R code analysis. &lt;a href=&quot;https://cran.r-project.org/web/packages/lintr/index.html&quot;&gt;https://cran.r-project.org/web/packages/lintr/index.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;codetools: code analysis tools for R. Default tools used by R CMD check. &lt;a href=&quot;https://cran.r-project.org/web/packages/codetools/index.html&quot;&gt;https://cran.r-project.org/web/packages/codetools/index.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;codecov, backend coverage tool for covr. &lt;a href=&quot;https://codecov.io/&quot;&gt;https://codecov.io/&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;day2-bioc&quot;&gt;Day2 BioC&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;cole trapnell: 
glm fit to detect single cell trajactory
lineage dependent genes 
single-cell ATAC-seq
TF-idf, tranfrom binary data to continious data&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;wenyi Wang
deconvolution of mixed gene expression in hetergenenity of samples (cell-type proportions)
Simply speaking, remvoe the heterogenity noise (normal within tumor), by asssuming a mixture model and bayesian statistics.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Karl Broman
interactive plot using D3 &lt;a href=&quot;http://d3js.org/&quot;&gt;http://d3js.org/&lt;/a&gt;
qtlchart &lt;a href=&quot;http://kbroman.org/qtlcharts/&quot;&gt;http://kbroman.org/qtlcharts/&lt;/a&gt;
ggvis &lt;a href=&quot;http://ggvis.rstudio.com/&quot;&gt;http://ggvis.rstudio.com/&lt;/a&gt;
coffeescript &lt;a href=&quot;http://coffeescript.org/&quot;&gt;http://coffeescript.org/&lt;/a&gt;
htmlwidgets for R &lt;a href=&quot;http://www.htmlwidgets.org/&quot;&gt;http://www.htmlwidgets.org/&lt;/a&gt;
JSFiddle for testing javascript &lt;a href=&quot;https://jsfiddle.net/&quot;&gt;https://jsfiddle.net/&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Leonard Goldstein
SGSeq, alternative splicing&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nicole Deflaux
Google genomics, Dream challenge&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tengfei
rabix &lt;a href=&quot;https://www.rabix.org&quot;&gt;https://www.rabix.org&lt;/a&gt;, docopt &lt;a href=&quot;http://docopt.org/&quot;&gt;http://docopt.org/&lt;/a&gt;, liftr, sbgr&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;day3-bioc&quot;&gt;Day3 BioC&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Zhijin Wu
Gene set analysis
Global test, TEGS (2013)
(GSA, Efron &amp;amp; Tibshirani 2007) same direction of genes in the pathway. 
take considerations of small but consistant change of all the genes in the gene set&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;questions 
- Not same direction in biological pathways
- PCA based method
- simulation vs real data evaluation 
- False positives, AUC during simulation 
- R package?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Artem Sokolov
Integrating prior biological knowledge using Generalized Elastic Nets
gelnet &lt;a href=&quot;https://cran.r-project.org/web/packages/gelnet/index.html&quot;&gt;https://cran.r-project.org/web/packages/gelnet/index.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;TCGA downloader 
mogsa: Multiple omics data integration and gene set analysis &lt;a href=&quot;http://www.bioconductor.org/packages/release/bioc/html/mogsa.html&quot;&gt;http://www.bioconductor.org/packages/release/bioc/html/mogsa.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;RTCGAToolbox: A new tool for exporting TCGA Firehose data &lt;a href=&quot;https://www.bioconductor.org/packages/devel/bioc/html/RTCGAToolbox.html&quot;&gt;https://www.bioconductor.org/packages/devel/bioc/html/RTCGAToolbox.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;SGSeq: Splice event detection and quantification from RNA-seq data
&lt;a href=&quot;http://bioconductor.org/packages/release/bioc/html/SGSeq.html&quot;&gt;http://bioconductor.org/packages/release/bioc/html/SGSeq.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ideas:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Drug-drug interaction (DsigDB, and TCGA data)&lt;/li&gt;
  &lt;li&gt;real-time meomory visuliztion for R&lt;/li&gt;
  &lt;li&gt;dynamic heatmap, vector-based editing (interactive plot ggvis)&lt;/li&gt;
  &lt;li&gt;code executing time estimate (like data.table does, prob some C code)&lt;/li&gt;
  &lt;li&gt;different type of errors (family wise type error)&lt;/li&gt;
  &lt;li&gt;Bayesian statistiscs summary (refresh basics)&lt;/li&gt;
  &lt;li&gt;normalization comparison for RNA-seq, miRNA-seq&lt;/li&gt;
  &lt;li&gt;DE analysis comparison of DESeq2, edgeR-robust&lt;/li&gt;
  &lt;li&gt;feature selection, iterative ensembel learning&lt;/li&gt;
  &lt;li&gt;update XBSeq,&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>StochasticvsDeterministic</title>
   <link href="/2015/07/08/StochasticvsDeterministic.html"/>
   <updated>2015-07-08T00:00:00-05:00</updated>
   <id>/2015/07/08/StochasticvsDeterministic</id>
   <content type="html">&lt;p&gt;A deterministic model没有stochastic的成分，input和output的关系是完全确定的。比如说linear regression或者non-linear的curve fitting都是属于determininistic model。Stochastic model，包含了randomness，同样的input会导致不同样的output，不同的statistical distribution, MCMC的simulation都属于stochastic process。&lt;/p&gt;

&lt;p&gt;source: &lt;a href=&quot;http://www.slideshare.net/sohail40/deterministic-vs-stochastic&quot;&gt;http://www.slideshare.net/sohail40/deterministic-vs-stochastic&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Applied predictive modeling</title>
   <link href="/2015/06/27/Applied-predictive-modeling.html"/>
   <updated>2015-06-27T00:00:00-05:00</updated>
   <id>/2015/06/27/Applied predictive modeling</id>
   <content type="html">&lt;h1 id=&quot;data-preprocessing&quot;&gt;Data preprocessing&lt;/h1&gt;

&lt;h3 id=&quot;centering-and-scaling&quot;&gt;Centering and scaling&lt;/h3&gt;

&lt;p&gt;Centering and scaling are generally used to improve numerical stability of some calculations&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PLS might benefit from centering and scaling&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;transformation&quot;&gt;Transformation&lt;/h3&gt;

&lt;p&gt;Transformation is generally used to remove skewness&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;log, inverse, square root transformation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Box-cox transformation:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
x^* =
\begin{cases}
\frac{x^\lambda - 1}{\lambda},  &amp; \text{if $\lambda$ $\neq$ 0} \\
log(x), &amp; \text{if $\lambda$ = 0}
\end{cases} %]]&gt;&lt;/script&gt;

</content>
 </entry>
 
 <entry>
   <title>收到Bioconductor年会的travel award</title>
   <link href="/2015/06/17/%E5%88%B0Bioconductor%E5%B9%B4%E4%BC%9A%E7%9A%84travel-award-Copy.html"/>
   <updated>2015-06-17T00:00:00-05:00</updated>
   <id>/2015/06/17/到Bioconductor年会的travel award - Copy</id>
   <content type="html">&lt;p&gt;最近刚刚收到Bioconductor 年会的travel award。有点小小的惊喜，毕竟最开始只是以试试的态度申请的，想必应该有挺多人去这个年会的。我也算是有幸能够目睹下Bioconductor本部啦。还有最近‘认识’了一位牛人，Hadley Wickham。dplyr 和 stringr都是出自此人之手； 统计PhD毕业，写代码的功夫也算了得。现在在Rstudio工作。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Time series analysis and its applications</title>
   <link href="/2015/04/22/Time-series-analysis-and-its-applications.html"/>
   <updated>2015-04-22T00:00:00-05:00</updated>
   <id>/2015/04/22/Time series analysis and its applications</id>
   <content type="html">&lt;p&gt;开一篇文章总结time series 相关领域的信息（常用模型， 基本概念等）。 主要是两本书的总结， 第一本是， Shumway的 Time series analysis and its applications. 第二本是Chatfield的 The analysis of Time Series: An introduction.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;White Noise, a collection of uncorrelated random variables, &lt;script type=&quot;math/tex&quot;&gt;w_t \sim wn(0, \sigma_w^2)&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Moving averages, average with intermediate neighbors in the past and future， &lt;script type=&quot;math/tex&quot;&gt;v_t = \frac{1}{3}(w_{t-1} + w_t + w_{t+1})&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Auto regression, &lt;script type=&quot;math/tex&quot;&gt;x_t = ax_{t-1} + bx_{t-2} + w_t&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Random walk with drift, &lt;script type=&quot;math/tex&quot;&gt;x_t = \sigma + x_{t-1} + w_t&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; is called the drift&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>各种不同算法的总结帖（持续更新）</title>
   <link href="/2015/04/20/Machine-learning-%E5%90%84%E7%A7%8D%E4%B8%8D%E5%90%8C%E7%AE%97%E6%B3%95%E7%9A%84%E6%80%BB%E7%BB%93%E5%B8%96-%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0.html"/>
   <updated>2015-04-20T00:00:00-05:00</updated>
   <id>/2015/04/20/Machine learning 各种不同算法的总结帖（持续更新）</id>
   <content type="html">&lt;p&gt;转眼间接触machine learning 已经半年多了， 现在开一个帖子写写关于不同machine learning 算法的总结帖。&lt;/p&gt;

&lt;h1 id=&quot;random-forest&quot;&gt;Random forest&lt;/h1&gt;

&lt;p&gt;Random forest 是基于decision tree的一种方法，简单的来说就是创建 a multitude of decision trees. 先bootstrap training data， 然后对每一个bootstrap， 创建一个decision tree。为了解决tree 与 tree之间可能有的correlation的问题，在每一个resampling的data上，仅仅只使用原始feature的一部分。在R上的这个可以用来tune的parameter是 mtry， classification 的problem default是 \( \sqrt{f} \). Regression 的 default 是 \( \frac{f}{3} \). 也因为此，random forest并不需要传统的cross validation。可以用其oob (out of bag error) 来进行筛选model。&lt;/p&gt;

&lt;p&gt;Random forest 的 error rate 取决于两个方面，&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;树与树之间的correlation， correlation越大，error也越大&lt;/li&gt;
  &lt;li&gt;每一个树的predictive power， predictive power 越强， error 越小&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以上两点都会随着mtry的增大而增大，减小而减少。所以会存在一个中间的optimal number 可以 tune for。&lt;/p&gt;

&lt;p&gt;Random forest的一些特征&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Random forest 可以用来estimate variable importance&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Permutation-based：基本流程就是，对于每一个tree的oob cases， random permute某一个variable，然后计算跟不permute之间的差异。然后取每个tree的average，计算出这个variable的raw imp score。然后，assume 树与树之间的score是independent的，计算出standard error。从而算出Z score。Assume normal distribution， 算出p value。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Gini impurity based：每一个针对某个variable的decision tree的分割，分下来的branch 都会比parent tree得gini impurity小。把所有针对于某个variable的分割的gini impurity decrease通加起来就会迅速的得到某一个variable的important score。通常会跟permutation-based方法结果类似。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;unexcelled in accuracy&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;但是，以我自己的使用经历来看，rf通常都会是中等偏上的结果。（待验证）&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;可以用来estimate missing values&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在所有同一个class的这个variable中求median（Non-categorical）或者是mode （categorical）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;第二种方式相对来说比较费时，但是相对精确。首先粗略估计一下missing value的值（可以用第一种方法来作为起始值），做一次rf，然后算sample之间的proximity，missing value的值就是weighted average或者weighted class frequency，weights就是proximity。然后循环继续同样过程，通常5-6次循环即可。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对于test set的missing data的处理，如果能够使用label的话，可以运用上面两种方式，如果不能使用label的话，假设每一个sample都belong to所有的class，然后去做filling。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Compute proximities between classes, 可以用来做cluster， outlier detection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在tree grow完成以后，将training data和oob一起过一遍tree，如果某一个sample跟另外一个在同一个terminal node里面，proximity加一。然后normalize到所有的tree&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;可以用来测设不同variable之间的interaction。（need to try sometime）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;interaction就是比如说，一个variablesplit会导致对于另外一个variable的split more/less likely。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;scaling&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;类似于MDS，不过是运用proximity。&lt;/p&gt;

&lt;h1 id=&quot;generalized-boosted-regression-models-gbm&quot;&gt;Generalized Boosted Regression Models (gbm)&lt;/h1&gt;

&lt;p&gt;其实现在还是不太清楚gbm是stand for Generalized Boosted Regression Models 还是，gradient boosted models。。（现在发现其实这俩种说法其实都是一个意思。。）&lt;/p&gt;

&lt;p&gt;说到gbm就得先提一提boosting的方法。boosting 也是ensemble learning的一种方法.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Adaboost: 最开始先以stage-wise的manner去construct a sequence of weak learners。在每一个stage，把classify错误的case 的weight增大，最后用一个additive model把所有的classifier combine到一起。&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Elements of statistical learning且读且感</title>
   <link href="/2015/04/18/Elements-of-statistical-learning%E4%B8%94%E8%AF%BB%E4%B8%94%E6%84%9F.html"/>
   <updated>2015-04-18T00:00:00-05:00</updated>
   <id>/2015/04/18/Elements of statistical learning且读且感</id>
   <content type="html">&lt;h2 id=&quot;liner-regression&quot;&gt;liner regression&lt;/h2&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;RSS(\beta) = \sum_{i=1}^n \left(y^i - {x_i^T}\beta\right)^2&lt;/script&gt;

&lt;p&gt;Model itself rely heavily on the assumption that a linear boundary is appropriate. It has low variance and potentially high bias.&lt;/p&gt;

&lt;h2 id=&quot;k-nearest-neighbors&quot;&gt;K nearest neighbors&lt;/h2&gt;

&lt;p&gt;Non-linear boundary. Do not depend on the underlying structure of the data and tend to have high variance and low bias.&lt;/p&gt;
</content>
 </entry>
 
 
</feed>
